{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet.ipynb","provenance":[],"authorship_tag":"ABX9TyNujKU8zyWaew6nR8P/qsmj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"B7n-m1KKWfpI","executionInfo":{"status":"ok","timestamp":1603991880152,"user_tz":-420,"elapsed":4669,"user":{"displayName":"Phương Vũ Thị","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBow1UFeHMgBvhlbsBTEjjSJU04nEDBggKDYWy=s64","userId":"05285126281615536544"}}},"source":["import os\n","import torch\n","import torchvision\n","import numpy as np\n","import pandas as pd\n","import torch.nn as nn\n","import torch.optim as optim\n","import matplotlib.pyplot as plt\n","import torch.nn.functional as F\n","from PIL import Image\n","from torchvision import transforms, datasets\n","from torch.utils.data import Dataset, DataLoader"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"NAClwpbyWmRL","executionInfo":{"status":"ok","timestamp":1603991884056,"user_tz":-420,"elapsed":1049,"user":{"displayName":"Phương Vũ Thị","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBow1UFeHMgBvhlbsBTEjjSJU04nEDBggKDYWy=s64","userId":"05285126281615536544"}},"outputId":"da0541b7-7a4b-4c92-ee3d-1f52e09f2b51","colab":{"base_uri":"https://localhost:8080/"}},"source":["# training batches of our network\n","EPOCHS = 15\n","# size of each batch\n","BATCH_SIZE = 512\n","\n","DEVICE = (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n","               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n","\n","print(torch.__version__)\n","print(DEVICE)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["1.6.0+cu101\n","cuda\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"g3v2ybnsWp95","executionInfo":{"status":"error","timestamp":1603991891438,"user_tz":-420,"elapsed":1792,"user":{"displayName":"Phương Vũ Thị","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgBow1UFeHMgBvhlbsBTEjjSJU04nEDBggKDYWy=s64","userId":"05285126281615536544"}},"outputId":"fc69978e-abe9-4d41-c77e-e6d2b934d597","colab":{"base_uri":"https://localhost:8080/","height":442}},"source":["train_csv = pd.read_csv('/content/drive/My Drive/Fashion Mnist/Fashion Mnist/fashion-mnist_train.csv')\n","test_csv = pd.read_csv('/content/drive/My Drive/Fashion Mnist/Fashion Mnist/fashion-mnist_test.csv')\n","\n","\n","print(train_csv.shape)\n","print(test_csv.shape)"],"execution_count":3,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-3-1ecd01056553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Fashion Mnist/Fashion Mnist/fashion-mnist_train.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Fashion Mnist/Fashion Mnist/fashion-mnist_test.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_csv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    684\u001b[0m     )\n\u001b[1;32m    685\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 452\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    454\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1176\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   2006\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2008\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2009\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/My Drive/Fashion Mnist/Fashion Mnist/fashion-mnist_train.csv'"]}]},{"cell_type":"code","metadata":{"id":"MZ2d9Ug8Wv3b"},"source":["print(train_csv.info())\n","print(train_csv.head())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tVI8I1XgWwxb"},"source":["class FashionDataset(Dataset):\n","    def __init__(self, data, transform=None):        \n","        self.fashion_MNIST = list(data.values)\n","        self.transform = transform\n","        \n","        label, image = [], []\n","        \n","        for i in self.fashion_MNIST:\n","            label.append(i[0])\n","            image.append(i[1:])\n","        self.labels = np.asarray(label)\n","        self.images = np.asarray(image).reshape(-1, 28, 28).astype('float32')\n","        \n","    def __len__(self):\n","        return len(self.images)\n","    \n","    def __getitem__(self, idx):\n","        label = self.labels[idx]\n","        image = self.images[idx]      \n","        \n","        if self.transform is not None:\n","            # transfrom the numpy array to PIL image before the transform function\n","            pil_image = Image.fromarray(np.uint8(image)) \n","            image = self.transform(pil_image)\n","            \n","        return image, label"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"872zSLq_W9ml"},"source":["AlexTransform = transforms.Compose([\n","    transforms.Resize((227, 227)),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.1307,), (0.3081,))\n","])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVEQ9yi4W-e8"},"source":["train_loader = DataLoader(\n","    FashionDataset(train_csv, transform=AlexTransform), \n","    batch_size=BATCH_SIZE, shuffle=True)\n","\n","test_loader = DataLoader(\n","    FashionDataset(test_csv, transform=AlexTransform), \n","    batch_size=BATCH_SIZE, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"eOGKZsCmXCmW"},"source":["# helper function to show an image\n","def matplotlib_imshow(img):\n","    img = img.mean(dim=0)\n","    img = img / 2 + 0.5     # unnormalize\n","    npimg = img.numpy()\n","    plt.imshow(npimg, cmap=\"Greys\")\n","\n","# get some random training images\n","dataiter = iter(train_loader)\n","images, labels = dataiter.next()\n","\n","# creat grid of images\n","img_grid = torchvision.utils.make_grid(images[0])\n","\n","# show images & labels\n","matplotlib_imshow(img_grid)\n","print(class_names[labels[0]])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"s0h_2tMEXG3m"},"source":["class fasion_mnist_alexnet(nn.Module):  \n","    def __init__(self):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=1, out_channels=96, kernel_size=11, stride=4, padding=0),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3, stride=2)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(96, 256, 5, 1, 2),\n","            nn.ReLU(),\n","            nn.MaxPool2d(3, 2)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(256, 384, 3, 1, 1),\n","            nn.ReLU()\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(384, 384, 3, 1, 1),\n","            nn.ReLU()\n","        )\n","        self.conv5 = nn.Sequential(\n","            nn.Conv2d(384, 256, 3, 1, 1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(3, 2)\n","        )\n","\n","        self.fc1 = nn.Linear(256 * 6 * 6, 4096)\n","        self.fc2 = nn.Linear(4096, 4096)\n","        self.fc3 = nn.Linear(4096, 10)\n","\n","    def forward(self, x):\n","        out = self.conv1(x)\n","        out = self.conv2(out)\n","        out = self.conv3(out)\n","        out = self.conv4(out)\n","        out = self.conv5(out)\n","        out = out.view(out.size(0), -1)\n","\n","        out = F.relu(self.fc1(out))  # 256*6*6 -> 4096\n","        out = F.dropout(out, 0.5)\n","        out = F.relu(self.fc2(out))\n","        out = F.dropout(out, 0.5)\n","        out = self.fc3(out)\n","        out = F.log_softmax(out, dim=1)\n","\n","        return out"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-zQg3OXpXJ7M"},"source":["model = fasion_mnist_alexnet().to(DEVICE)\n","criterion = F.nll_loss\n","optimizer = optim.Adam(model.parameters())"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"smXl6zDKXK1G"},"source":["def train(model, device, train_loader, optimer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        target = target.type(torch.LongTensor)\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = criterion(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if (batch_idx + 1) % 30 == 0:\n","            print(\"Train Epoch:{} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\".format(\n","                epoch, batch_idx * len(data), len(train_loader.dataset),\n","                100. * batch_idx / len(train_loader), loss.item()))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WT2QWqAAXN3o"},"source":["def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, target, reduction='sum').item()\n","            pred = output.max(1, keepdim=True)[1]\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","        test_loss /= len(test_loader.dataset)  # loss之和除以data数量 -> mean\n","        print(\"\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n\".format(\n","            test_loss, correct, len(test_loader.dataset), 100. * correct / len(test_loader.dataset)))\n","        print('='*50)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"e0yj6ftEXQiu"},"source":["for epoch in range(1, EPOCHS+1):\n","    train(model, DEVICE, train_loader, optimizer, epoch)\n","    test(model, DEVICE, test_loader)"],"execution_count":null,"outputs":[]}]}